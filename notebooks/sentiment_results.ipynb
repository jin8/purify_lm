{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/st2/myung/anaconda3/envs/pytorch/bin/python\r\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/v6/myung/iclr/purify_lm\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import json\n",
    "import codecs\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "%cd ..  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sentiment_results(models_dict, max_gens=None):\n",
    "    res = {}\n",
    "    for model in tqdm(models_dict):\n",
    "        df = pd.read_json(models_dict[model], lines=True)[:max_gens]\n",
    "        sentiment_labels = df.generations.apply(lambda x: [y['label'] for y in x])\n",
    "        positive_proportion = sentiment_labels.apply(lambda x: np.sum([1 for y in x if y == 'POSITIVE'])/len(x))\n",
    "        res[model] = {\n",
    "            'positive_proportion': positive_proportion.mean()\n",
    "        }\n",
    "        # read automatic evaluation\n",
    "        \"\"\"\n",
    "        with open(Path(os.path.dirname(models_dict[model])) / 'eval_results.txt', 'r') as fo:\n",
    "            for i, line in enumerate(fo):\n",
    "                if i < 3:\n",
    "                    print(line)\n",
    "                    dist_n = float(line.rstrip().replace(f'dist-{i+1} = ', ''))\n",
    "                    res[model][f'dist-{i+1}'] = dist_n\n",
    "                elif i == 3:\n",
    "                    print(line)\n",
    "                    ppl = float(line.replace('perplexity = ', '').strip('\\n').strip())\n",
    "                    res[model]['perplexity'] = ppl\n",
    "        \"\"\"\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_average(neutral_prompts_res, adversarial_prompts_res, key):\n",
    "    \"\"\"\n",
    "    return weighted average of dist-n or perplexity value across neural prompts (5k) and adversarial prompts (2.5k)\n",
    "    \"\"\"\n",
    "    return np.average([neutral_prompts_res[model][key], adversarial_prompts_res[model][key]], weights=[2,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## positive steering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results corresponding to the top half of Table 3\n",
    "\n",
    "NEUTRAL_DIR = Path('generations/sentiment/neutral_prompts/')\n",
    "NEG_DIR = Path('generations/sentiment/negative_prompts/')\n",
    "'''\n",
    "    'GPT-2': {\n",
    "        'neutral_path': NEUTRAL_DIR / 'gpt2/prompted_gens_gpt2.jsonl',\n",
    "        'neg_path': NEG_DIR / 'gpt2/prompted_gens_gpt2.jsonl',\n",
    "    },\n",
    "    'PPLM': {\n",
    "        'neutral_path': NEUTRAL_DIR / 'pplm/positive/prompted_gens_pplm.jsonl',\n",
    "        'neg_path': NEG_DIR / 'pplm/prompted_gens_pplm.jsonl'\n",
    "    },\n",
    "    'DAPT': {\n",
    "        'neutral_path': NEUTRAL_DIR / 'dapt/positive/prompted_gens_gpt2.jsonl',\n",
    "        'neg_path': NEG_DIR / 'dapt/prompted_gens_gpt2.jsonl',\n",
    "    },\n",
    "    'GeDi': {\n",
    "        'neutral_path': NEUTRAL_DIR / 'gedi/positive/prompted_gens_gedi.jsonl',\n",
    "        'neg_path': NEG_DIR / 'gedi/prompted_gens_gedi.jsonl'\n",
    "    },\n",
    "    'CTRL': {\n",
    "        'neutral_path': NEUTRAL_DIR / 'ctrl/positive/prompted_gens_ctrl.jsonl',\n",
    "        'neg_path': NEG_DIR / 'ctrl/prompted_gens_ctrl.jsonl'\n",
    "    },\n",
    "    'Expert': {\n",
    "        'neutral_path': NEUTRAL_DIR / 'expert/positive/prompted_gens_gpt2.jsonl',\n",
    "        'neg_path': NEG_DIR / 'expert/prompted_gens_gpt2.jsonl',\n",
    "    },\n",
    "    #'DExperts (anti-only)': {\n",
    "    #    'neutral_path': NEUTRAL_DIR / 'dexperts_anti-only/a-2.0/prompted_gens_dexperts.jsonl',\n",
    "    #    'neg_path': NEG_DIR / 'dexperts_anti-only/a-2.0/prompted_gens_dexperts.jsonl',\n",
    "    #},\n",
    "    'DExperts (small)': {\n",
    "        'neutral_path': NEUTRAL_DIR / 'dexperts/small_experts/positive/prompted_gens_dexperts.jsonl',\n",
    "        'neg_path': NEG_DIR / 'dexperts/small_experts/prompted_gens_dexperts.jsonl'\n",
    "    },\n",
    "    #'DExperts (medium)': {\n",
    "    #    'neutral_path': NEUTRAL_DIR / 'dexperts/medium_experts/positive/prompted_gens_dexperts.jsonl',\n",
    "    #    'neg_path': NEG_DIR / 'dexperts/small_experts/prompted_gens_dexperts.jsonl'\n",
    "    #},\n",
    "\n",
    "    'fuse_style_ep10': {\n",
    "        'neutral_path':'our_generations/prompted_sentiment-10k/neutral_prompts/fuse_style_ep10/positive/prompted_gens_style-gpt2-none.jsonl',\n",
    "        'neg_path': 'our_generations/prompted_sentiment-10k/negative_prompts/fuse_style_ep10/positive/prompted_gens_style-gpt2-none.jsonl'\n",
    "    },\n",
    "    \n",
    "    'fuse_style_ep20': {\n",
    "        'neutral_path':'our_generations/prompted_sentiment-10k/neutral_prompts/fuse_style_ep20/positive/prompted_gens_style-gpt2-none.jsonl',\n",
    "        'neg_path': 'our_generations/prompted_sentiment-10k/negative_prompts/fuse_style_ep20/positive/prompted_gens_style-gpt2-none.jsonl'\n",
    "    },\n",
    "    'fuse_style_ep30': {\n",
    "        'neutral_path':'our_generations/prompted_sentiment-10k/neutral_prompts/fuse_style_ep30/positive/prompted_gens_style-gpt2-none.jsonl',\n",
    "        'neg_path': 'our_generations/prompted_sentiment-10k/negative_prompts/fuse_style_ep30/positive/prompted_gens_style-gpt2-none.jsonl'\n",
    "    },\n",
    "    'fuse_rev_style_contrast0.25_ep100': {\n",
    "        'neutral_path':'our_generations/prompted_sentiment-10k/neutral_prompts/fuse_rev_style_contrast0.25_ep100/positive/prompted_gens_style-gpt2-none.jsonl',\n",
    "        'neg_path': 'our_generations/prompted_sentiment-10k/negative_prompts/fuse_rev_style_contrast0.25_ep100/positive/prompted_gens_style-gpt2-none.jsonl'\n",
    "    },\n",
    "    'fuse_rev_style_pred_contrast1.0_ep30': {\n",
    "        'neutral_path':'our_generations/prompted_sentiment-10k/neutral_prompts/fuse_rev_style_pred_contrast1.0_ep30/positive/prompted_gens_style-gpt2-attr.jsonl',\n",
    "        'neg_path': 'our_generations/prompted_sentiment-10k/negative_prompts/fuse_rev_style_pred_contrast1.0_ep30/positive/prompted_gens_style-gpt2-attr.jsonl'\n",
    "    },\n",
    "    'fuse_rev_style_pred_contrast1.0_ep50': {\n",
    "        'neutral_path':'our_generations/prompted_sentiment-10k/neutral_prompts/fuse_rev_style_pred_contrast1.0_ep50/positive/prompted_gens_style-gpt2-attr.jsonl',\n",
    "        'neg_path': 'our_generations/prompted_sentiment-10k/negative_prompts/fuse_rev_style_pred_contrast1.0_ep50/positive/prompted_gens_style-gpt2-attr.jsonl'\n",
    "    },\n",
    "    'fuse_rev_style_pred_contrast1.0_ep30_past': {\n",
    "        'neutral_path':'our_generations/prompted_sentiment-10k/neutral_prompts/fuse_rev_style_pred_contrast1.0_ep30/positive/prompted_gens_style-gpt2-attr_past.jsonl',\n",
    "        'neg_path': 'our_generations/prompted_sentiment-10k/negative_prompts/fuse_rev_style_pred_contrast1.0_ep30/positive/prompted_gens_style-gpt2-attr_past.jsonl'\n",
    "    },\n",
    "    'fuse_rev_style_pred_contrast1.0_ep50_past': {\n",
    "        'neutral_path':'our_generations/prompted_sentiment-10k/neutral_prompts/fuse_rev_style_pred_contrast1.0_ep50/positive/prompted_gens_style-gpt2-attr_past.jsonl',\n",
    "        'neg_path': 'our_generations/prompted_sentiment-10k/negative_prompts/fuse_rev_style_pred_contrast1.0_ep50/positive/prompted_gens_style-gpt2-attr_past.jsonl'\n",
    "    },\n",
    "'''\n",
    "models = {\n",
    "    'fuse_rev_style_pred_contrast1.0_ep30_with_project': {\n",
    "        'neutral_path':'our_generations/prompted_sentiment-10k/neutral_prompts/fuse_rev_style_pred_contrast1.0_ep30_with_project/positive/prompted_gens_style-gpt2-attr.jsonl',\n",
    "        'neg_path': 'our_generations/prompted_sentiment-10k/negative_prompts/fuse_rev_style_pred_contrast1.0_ep30_with_project/positive/prompted_gens_style-gpt2-attr.jsonl'\n",
    "    },\n",
    "    'fuse_rev_style_pred_contrast1.0_ep30_with_project_past': {\n",
    "        'neutral_path':'our_generations/prompted_sentiment-10k/neutral_prompts/fuse_rev_style_pred_contrast1.0_ep30_with_project/positive/prompted_gens_style-gpt2-attr_past.jsonl',\n",
    "        'neg_path': 'our_generations/prompted_sentiment-10k/negative_prompts/fuse_rev_style_pred_contrast1.0_ep30_with_project/positive/prompted_gens_style-gpt2-attr_past.jsonl'\n",
    "    },\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  2.17it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  5.05it/s]\n"
     ]
    }
   ],
   "source": [
    "# read sentiment control results\n",
    "neutral_prompts_res = read_sentiment_results({m: p['neutral_path'] for m,p in models.items()})\n",
    "neg_prompts_res = read_sentiment_results({m: p['neg_path'] for m,p in models.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fuse_rev_style_pred_contrast1.0_ep30_with_project': {'positive_proportion': 0.5632}, 'fuse_rev_style_pred_contrast1.0_ep30_with_project_past': {'positive_proportion': 0.3881280000000019}}\n",
      "{'fuse_rev_style_pred_contrast1.0_ep30_with_project': {'neutral_prompts': 75.78, 'neg_prompts': 56.32}, 'fuse_rev_style_pred_contrast1.0_ep30_with_project_past': {'neutral_prompts': 70.50880000000045, 'neg_prompts': 38.812800000000195}}\n"
     ]
    }
   ],
   "source": [
    "positive_steering_res = {}\n",
    "#assert set(neutral_prompts_res.keys()) == set(neg_prompts_res.keys())\n",
    "#print(neutral_prompts_res)\n",
    "print(neg_prompts_res)\n",
    "for model in neg_prompts_res.keys():\n",
    "    positive_steering_res[model] = {\n",
    "        'neutral_prompts': neutral_prompts_res[model]['positive_proportion']*100,\n",
    "        'neg_prompts': neg_prompts_res[model]['positive_proportion']*100,\n",
    "        #'dist-1': weighted_average(neutral_prompts_res, neg_prompts_res, 'dist-1'),\n",
    "        #'dist-2': weighted_average(neutral_prompts_res, neg_prompts_res, 'dist-2'),\n",
    "        #'dist-3': weighted_average(neutral_prompts_res, neg_prompts_res, 'dist-3'),\n",
    "        #'perplexity': weighted_average(neutral_prompts_res, neg_prompts_res, 'perplexity'),\n",
    "    }\n",
    "print(positive_steering_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neutral_prompts</th>\n",
       "      <th>neg_prompts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fuse_rev_style_pred_contrast1.0_ep30_with_project_past</th>\n",
       "      <td>70.51</td>\n",
       "      <td>38.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fuse_rev_style_pred_contrast1.0_ep30_with_project</th>\n",
       "      <td>75.78</td>\n",
       "      <td>56.32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    neutral_prompts  \\\n",
       "fuse_rev_style_pred_contrast1.0_ep30_with_proje...            70.51   \n",
       "fuse_rev_style_pred_contrast1.0_ep30_with_project             75.78   \n",
       "\n",
       "                                                    neg_prompts  \n",
       "fuse_rev_style_pred_contrast1.0_ep30_with_proje...        38.81  \n",
       "fuse_rev_style_pred_contrast1.0_ep30_with_project         56.32  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(positive_steering_res).transpose().sort_values(by='neg_prompts', ascending=True).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# negative steering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results corresponding to the bottom  half of Table 3\n",
    "\n",
    "NEUTRAL_DIR = Path('generations/sentiment/neutral_prompts/')\n",
    "POS_DIR = Path('generations/sentiment/positive_prompts/')\n",
    "\n",
    "models = {\n",
    "    'GPT-2': {\n",
    "        'neutral_path': NEUTRAL_DIR / 'gpt2/prompted_gens_gpt2.jsonl',\n",
    "        'pos_path': POS_DIR / 'gpt2/prompted_gens_gpt2.jsonl',\n",
    "    },\n",
    "    'PPLM': {\n",
    "        'neutral_path': NEUTRAL_DIR / 'pplm/negative/prompted_gens_pplm.jsonl',\n",
    "        'pos_path': POS_DIR / 'pplm/prompted_gens_pplm.jsonl'\n",
    "    },\n",
    "    'DAPT': {\n",
    "        'neutral_path': NEUTRAL_DIR / 'dapt/negative/prompted_gens_gpt2.jsonl',\n",
    "        'pos_path': POS_DIR / 'dapt/prompted_gens_gpt2.jsonl',\n",
    "    },\n",
    "    'GeDi': {\n",
    "        'neutral_path': NEUTRAL_DIR / 'gedi/negative/prompted_gens_gedi.jsonl',\n",
    "        'pos_path': POS_DIR / 'gedi/prompted_gens_gedi.jsonl'\n",
    "    },\n",
    "    'CTRL': {\n",
    "        'neutral_path': NEUTRAL_DIR / 'ctrl/negative/prompted_gens_ctrl.jsonl',\n",
    "        'pos_path': POS_DIR / 'ctrl/prompted_gens_ctrl.jsonl'\n",
    "    },\n",
    "    'Expert': {\n",
    "        'neutral_path': NEUTRAL_DIR / 'expert/negative/prompted_gens_gpt2.jsonl',\n",
    "        'pos_path': POS_DIR / 'expert/prompted_gens_gpt2.jsonl',\n",
    "    },\n",
    "    'DExperts (anti-only)': {\n",
    "        'neutral_path': NEUTRAL_DIR / 'dexperts_anti-only/a--2.0/prompted_gens_dexperts.jsonl',\n",
    "        'pos_path': POS_DIR / 'dexperts_anti-only/a--2.0/prompted_gens_dexperts.jsonl',\n",
    "    },\n",
    "    'DExperts (large)': {\n",
    "        'neutral_path': NEUTRAL_DIR / 'dexperts/large_experts/negative/prompted_gens_dexperts.jsonl',\n",
    "        'pos_path': POS_DIR / 'dexperts/large_experts/prompted_gens_dexperts.jsonl'\n",
    "    },\n",
    "    'DExperts (medium)': {\n",
    "        'neutral_path': NEUTRAL_DIR / 'dexperts/medium_experts/negative/prompted_gens_dexperts.jsonl',\n",
    "        'pos_path': POS_DIR / 'dexperts/medium_experts/prompted_gens_dexperts.jsonl'\n",
    "    },\n",
    "    'DExperts (small)': {\n",
    "        'neutral_path': NEUTRAL_DIR / 'dexperts/small_experts/negative/prompted_gens_dexperts.jsonl',\n",
    "        'pos_path': POS_DIR / 'dexperts/small_experts/prompted_gens_dexperts.jsonl'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read sentiment control results\n",
    "neutral_prompts_res = read_sentiment_results({m: p['neutral_path'] for m,p in models.items()})\n",
    "pos_prompts_res = read_sentiment_results({m: p['pos_path'] for m,p in models.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_steering_res = {}\n",
    "assert set(neutral_prompts_res.keys()) == set(pos_prompts_res.keys())\n",
    "for model in neutral_prompts_res.keys():\n",
    "    negative_steering_res[model] = {\n",
    "        'neutral_prompts': neutral_prompts_res[model]['positive_proportion']*100,\n",
    "        'pos_prompts': pos_prompts_res[model]['positive_proportion']*100,\n",
    "        'dist-1': weighted_average(neutral_prompts_res, pos_prompts_res, 'dist-1'),\n",
    "        'dist-2': weighted_average(neutral_prompts_res, pos_prompts_res, 'dist-2'),\n",
    "        'dist-3': weighted_average(neutral_prompts_res, pos_prompts_res, 'dist-3'),\n",
    "        'perplexity': weighted_average(neutral_prompts_res, pos_prompts_res, 'perplexity'),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(negative_steering_res).transpose().sort_values(by='neutral_prompts', ascending=False).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hyperparameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GENS_DIR = Path('generations/sentiment/neutral_prompts/')\n",
    "sizes = ['large', 'medium', 'small']\n",
    "size_dict = {size: defaultdict(dict) for size in sizes}\n",
    "\n",
    "for size in sizes:\n",
    "    dexperts_dir = Path(f'dexperts/{size}_experts')\n",
    "\n",
    "    for folder in os.listdir(GENS_DIR / dexperts_dir):\n",
    "        splits = folder.split('-')\n",
    "        if len(splits) >= 2:\n",
    "            a = '-' + splits[-1] if len(splits) == 3 else splits[-1]\n",
    "            a = float(a)\n",
    "            size_dict[size][a] = GENS_DIR / dexperts_dir / f'{folder}/prompted_gens_dexperts.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "small_res = read_sentiment_results(size_dict['small'], max_gens=1000)\n",
    "small_res_df = pd.DataFrame(small_res).transpose()\n",
    "medium_res = read_sentiment_results(size_dict['medium'], max_gens=1000)\n",
    "medium_res_df = pd.DataFrame(medium_res).transpose()\n",
    "large_res = read_sentiment_results(size_dict['large'], max_gens=1000)\n",
    "large_res_df = pd.DataFrame(large_res).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(res_df, label, axes):\n",
    "    ax = axes[0]\n",
    "    pos_hyperparam_res_df = res_df.loc[res_df.index >= 2.0]\n",
    "    sns.lineplot(x=pos_hyperparam_res_df['perplexity'], y=pos_hyperparam_res_df['positive_proportion'], ax=ax, marker='o', dashes=False, label=label)\n",
    "    for i, row in pos_hyperparam_res_df.iterrows():\n",
    "        x = row['perplexity']\n",
    "        y = row['positive_proportion']\n",
    "        ax.text(x=x, y=y, s=i)\n",
    "    \n",
    "    ax = axes[1]\n",
    "    neg_hyperparam_res_df = res_df.loc[res_df.index <= -2.0]\n",
    "    sns.lineplot(x=neg_hyperparam_res_df['perplexity'], y=neg_hyperparam_res_df['positive_proportion'], ax=ax, marker='o', dashes=False, label=label)\n",
    "    for i, row in neg_hyperparam_res_df.iterrows():\n",
    "        x = row['perplexity']\n",
    "        y = row['positive_proportion']\n",
    "        ax.text(x=x, y=y, s=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "fig, axes = plt.subplots(2, 1, figsize=(8,6))\n",
    "plt.style.use('seaborn-white')\n",
    "fig.tight_layout()\n",
    "\n",
    "plot(small_res_df, label='Small experts', axes=axes)\n",
    "plot(medium_res_df, label='Medium experts', axes=axes)\n",
    "plot(large_res_df, label='Large experts', axes=axes)\n",
    "\n",
    "ax = axes[0]\n",
    "ax.set_xlabel(' ')\n",
    "ax.set_ylabel('% Positive', fontsize=13)\n",
    "ax.set_title('Positive steering')\n",
    "ax.legend()\n",
    "\n",
    "ax = axes[1]\n",
    "ax.set_xlabel('Perplexity', fontsize=13)\n",
    "ax.set_ylabel('% Positive', fontsize=13)\n",
    "ax.set_title('Negative steering')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/sentiment_v_perplexity.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
